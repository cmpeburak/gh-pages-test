window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "pipeline.udeml.utils", "modulename": "pipeline.udeml.utils", "type": "module", "doc": "<p>Udeml Documentation</p>\n"}, {"fullname": "pipeline.udeml.utils.cacheutils", "modulename": "pipeline.udeml.utils.cacheutils", "type": "module", "doc": "<p>Utilities related to caching function results.</p>\n"}, {"fullname": "pipeline.udeml.utils.cacheutils.get_func_name", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "get_func_name", "type": "function", "doc": "<p></p>\n", "signature": "(func: Callable, include_module: bool = True) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.get_hash", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "get_hash", "type": "function", "doc": "<p></p>\n", "signature": "(x: Any) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.HashSafeWrapper", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "HashSafeWrapper", "type": "class", "doc": "<p>Class for wrapping objects to make them safe for use with memorize.</p>\n\n<p>The main use of this class is to wrap functions and classes which need to be\npassed as arguments to <code>memorize</code>. By default, the class will take the source of\nthe function or class and keep its hash on the <code>__hash_override__</code> attribute as\nrequired by <code>memorize</code>. To actually decorate your functions, make use of\n<code>wrap_for_memorize</code> function defined in this module.</p>\n"}, {"fullname": "pipeline.udeml.utils.cacheutils.HashSafeWrapper.__init__", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "HashSafeWrapper.__init__", "type": "function", "doc": "<p>Get a HashSafeWrapper instance.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>obj:</strong>  Any object (typically a function or class).</li>\n<li><strong>strict:</strong>  Whether to get the source code for functions and classes. If False,\nwill try to use <code>__name__</code> or simply get the hash of the object string.\n(defaults to True)</li>\n<li><strong>hash_salt:</strong>  An optional salt used for hashing. This can be useful for\ndebugging. (defaults to None and no salt will be used).</li>\n<li><strong>hash_override:</strong>  Provide a hash to override all other behavior. This can be\nuseful for debugging. (defaults to None)</li>\n</ul>\n", "signature": "(\n    self,\n    obj: Any,\n    strict: bool = True,\n    hash_salt: Union[Any, NoneType] = None,\n    hash_override: Union[str, NoneType] = None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.HashSafeWrapper.KNOWN_TYPES", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "HashSafeWrapper.KNOWN_TYPES", "type": "variable", "doc": "<p></p>\n", "default_value": " = ['class', 'function']"}, {"fullname": "pipeline.udeml.utils.cacheutils.HashSafeWrapper.override_hash", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "HashSafeWrapper.override_hash", "type": "function", "doc": "<p></p>\n", "signature": "(self, hash_: str)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.HashSafeWrapper.obj", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "HashSafeWrapper.obj", "type": "variable", "doc": "<p></p>\n"}, {"fullname": "pipeline.udeml.utils.cacheutils.wrap_for_memorize", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "wrap_for_memorize", "type": "function", "doc": "<p>Decorator generator for making an object hashable for use with memorize.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>strict:</strong>  Whether to get the source code for functions and classes. If False,\nwill try to use <code>__name__</code> or simply get the hash of the object string.\n(defaults to True)</li>\n<li><strong>hash_salt:</strong>  An optional salt used for hashing. This can be useful for\ndebugging. (defaults to None and no salt will be used).</li>\n<li><strong>hash_override:</strong>  Provide a hash to override all other behavior. This can be\nuseful for debugging. (defaults to None)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Decorator generator function that is safe to be used as argument to <code>memorize</code>d\n  function.</p>\n</blockquote>\n", "signature": "(\n    strict: bool = True,\n    hash_salt: Union[Any, NoneType] = None,\n    hash_override: Union[str, NoneType] = None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.memorize", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "memorize", "type": "function", "doc": "<p>Decorator for persisting results of generic functions. Note that the decorated\nfunction will accept the following special arguments starting with two and three\nunderscores, the ones with three underscores will be not be passed to the\nunderlying function whereas the ones with two underscores will be passed on.</p>\n\n<p>__ignore_cache (bool): Whether to ignore the caching mechanism completely.\n__force_refresh (bool): Whether the cache should be refreshed even if it exists.\n__raise_on_error (bool): whether error in saving cache file should raise an\n    exception. (Defaults to True)\n__raise_on_cache_miss (bool): whether cache miss should raise an exception. This\n    is often useful for debugging cache misses (Defaults to False).\n__cache_key_prepend (str): optional string to append to the cache file name.\n__cache_key_append (str): optional string to append to cache file name.\n__out_dict (Optional[Dict]): A dictionary which can be passed in to be populated\n    with the cache file paths.\n__local_dir (str): override for <code>local_dir</code>.\n__s3_dir (Optional[str]): override for <code>s3_dir</code>.\n__save_metadata (bool): override for <code>save_metadata</code>.\n__kwargs_formatters (List[Tuple[str, Callable]]): override for\n    <code>kwargs_formatters</code>.\n__num_args_to_ignore (int): override for <code>num_args_to_ignore</code>.\n__func_name_override (Optional[str]): override for <code>func_name_override</code>.\n__strict (bool): override for <code>strict</code>.\n__max_filename_len (int): override for <code>max_filename_len</code>.\n__file_ext (Optional[str]): override for <code>file_ext</code>.\n__dump_format (str): override for <code>dump_format</code>.\n__save_func (Optional[Callable[[Any, str], bool]]): override for <code>save_func</code>.\n__load_func (Optional[Callable[[str], Any]]): override for <code>load_func</code>.\n__logger (logging.Logger|Callable): override for <code>logger</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>local_dir:</strong>  local cache directory</li>\n<li><strong>s3_dir:</strong>  path to s3 in format \"s3://<bucket>/<object_prefix>\"</li>\n<li><strong>save_metadata:</strong>  Whether to save metadata about the function call.</li>\n<li><strong>kwargs_formatters:</strong>  A list of keyword args and their value_formatter\nfunctions. A value_formatter function is a function that takes the arg\nand returns a suitable representation of it to be included in the cache\nfile name. Provide None or map to a constant to exclude arg from the\ncache key.</li>\n<li><strong>is_instance_method:</strong>  Whether the decorated function is an instance method.\nIf it is the case, then the first implicit argument (a.k.a. <code>self</code>) will be\nadded to the hash which means the instance should handle <code>get_hash()</code>\ncorrectly by implementing the <code>__hash_override__</code> property. (Defaults to\nFalse).</li>\n<li><strong>num_args_to_ignore:</strong>  Number of args which will not be taken into\naccount in the creation of the cache_key. This can be useful for\nfunctions where the first arguments are non-hashable accessor like a\nsession or shell, etc. Note that if you decorate a class member, the\nfirst arg will be the implicit <code>self</code> argument. For such cases, you can\neither set to 1 to ignore the self, or set <code>is_instance_method</code> to True\nand implement <code>__hash_override__</code> property of the instance for correct\nhashing of the object instance (Defaults to 0).</li>\n<li><strong>create_local_dir:</strong>  whether the cache directory should be created if\nit does not exist. (Defaults to True).</li>\n<li><strong>strict:</strong>  whether the cache should be invalidated when the function\nimplementation is changed. (Defaults to False).</li>\n<li><strong>func_name_override (Optional[str]):</strong>  override for function name in case you\nwant a different name than the actual function name. (Defaults to None\nand will use the actual function name).</li>\n<li><strong>max_filename_len:</strong>  maximum length of the cache file name (OSX seems to not\nlike filenames that are more than 255 characters long, so tha is the\ndefault). In file name is longer, the the long part will be replaced with\na hash.</li>\n<li><strong>hash_len:</strong>  length of hexadecimal hash string.</li>\n<li><strong>file_ext:</strong>  File extension. (default: None and will fall back to value of\n<code>dump_format</code>)</li>\n<li><strong>dump_format:</strong>  format of result if it is a DataFrame. Must be one of\n{'dill', 'joblib', 'parquet', 'csv'} (default: 'joblib')</li>\n<li><strong>save_func:</strong>  function that takes the result and the path and saves it.</li>\n<li><strong>load_func:</strong>  function that takes the path to a result and loads it.</li>\n<li><strong>logger:</strong>  logging.Logger object, print, or any other logging function.</li>\n</ul>\n", "signature": "(\n    local_dir: str,\n    s3_dir: Union[str, NoneType] = None,\n    save_metadata: bool = True,\n    kwargs_formatters: List[Tuple[str, Callable[[Any], str]]] = None,\n    is_instance_method: bool = False,\n    func_name_override: Union[str, NoneType] = None,\n    num_args_to_ignore: int = 0,\n    create_local_dir: bool = True,\n    strict: bool = False,\n    max_filename_len: int = 255,\n    hash_len: int = 16,\n    file_ext: Union[str, NoneType] = None,\n    dump_format: str = 'joblib',\n    save_func: Union[Callable[[Any, str], bool], NoneType] = None,\n    load_func: Union[Callable[[str], Any], NoneType] = None,\n    logger: Union[logging.Logger, Callable[[str], NoneType]] = None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.cacheutils.memorize_with_hashable_args", "modulename": "pipeline.udeml.utils.cacheutils", "qualname": "memorize_with_hashable_args", "type": "function", "doc": "<p>Decorator for fast caching of functions which have hashable args.\nNote that it will convert np.NaN to None for caching to avoid this common\ncase causing a cache miss.</p>\n", "signature": "(func)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils", "modulename": "pipeline.udeml.utils.configutils", "type": "module", "doc": "<p>Utilities for application configuration</p>\n"}, {"fullname": "pipeline.udeml.utils.configutils.read_config_file", "modulename": "pipeline.udeml.utils.configutils", "qualname": "read_config_file", "type": "function", "doc": "<p>Reads the config file in the given path.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>file_path:</strong>  Config file full path.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Configuration properties as a dictionary.</p>\n</blockquote>\n", "signature": "(file_path: str) -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils.get_spark_defaults_config", "modulename": "pipeline.udeml.utils.configutils", "qualname": "get_spark_defaults_config", "type": "function", "doc": "<p>Returns a dictionary containing spark-defaults\nconfiguration for an application.</p>\n\n<h6 id=\"it-checks-three-sources-in-order-of-priority\">It checks three sources in order of priority</h6>\n\n<blockquote>\n  <ul>\n  <li>If <code>spark_defaults_dict</code> is given, it directly returns that dictionary.</li>\n  <li>If <code>spark_defaults_file_path</code> is given, it reads the config file\n  in the given path, and returns the <code>spark-defaults</code> section.</li>\n  <li>If none of the above is given, it looks for the application folder\n  and reads the file named <code>config.file</code> in that folder.</li>\n  </ul>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>spark_defaults_dict:</strong>  Dictionary containing spark-defaults configuration</li>\n<li><strong>spark_defaults_file_path:</strong>  Path to a config file containing\nspark-defaults configuration</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary containing spark-default configuration for the application.</p>\n</blockquote>\n", "signature": "(\n    spark_defaults_dict: Union[Dict, NoneType] = None,\n    spark_defaults_file_path: Union[str, NoneType] = None\n) -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils.get_proj_dir", "modulename": "pipeline.udeml.utils.configutils", "qualname": "get_proj_dir", "type": "function", "doc": "<p>Gets the project directory by checking the environment variables.\nRaises exception if the corresponding variable is not previously set.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Path to the project directory.</p>\n</blockquote>\n", "signature": "() -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils.update_emr_config_with_spark_defaults_overrides", "modulename": "pipeline.udeml.utils.configutils", "qualname": "update_emr_config_with_spark_defaults_overrides", "type": "function", "doc": "<p>Updates EMR-style configuration using the given spark-defaults\nconfiguration dictionary.</p>\n\n<p>If spark_defaults_overrides is not null or empty,\nthe returned emr_config is guaranteed to have \"spark-defaults\" classification.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>emr_config:</strong>  See parameter <code>emr_config</code>\nin <code>udeml.settings.deploy.run_remote_job</code>.</li>\n<li><strong>spark_defaults_overrides:</strong>  A dictionary to override spark-defaults properties.\nKey-value pairs the in this dictionary are passed as the property names\nand their values to the spark-defaults section in the emr_config.</li>\n<li><strong>override_if_spark_defaults_exist:</strong>   If False, values are not updated\nif there are already some properties of spark-defaults configuration.\nIf True, the existing values are overridden.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary or a list of dictionaries of EMR-style configuration\n  including \"spark-defaults\" classification.</p>\n</blockquote>\n", "signature": "(\n    emr_config: Union[dict, List[dict], NoneType],\n    spark_defaults_overrides: Union[Dict[str, str], NoneType],\n    override_if_spark_defaults_exist: bool\n) -> Union[dict, List[dict]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils.update_emr_config_with_env_vars", "modulename": "pipeline.udeml.utils.configutils", "qualname": "update_emr_config_with_env_vars", "type": "function", "doc": "<p>Updates EMR-style configuration and passes environment variables\nas the Properties of spark-defaults config.</p>\n\n<p>Reasoning behind this is that we've observed some weird bug\nwhere env vars would not be passed for spark 3.0.\nThe fix to this is to stop using the env parameter of PySparkProcessor\nand instead use the Properties of the config.</p>\n\n<p>We always want to override its properties if there is a \"spark-defaults\"\nclassification in the <code>emr_config</code> given to the deploy.py, that's why we set\n<code>update_if_spark_defaults_exist</code> parameter to True.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>emr_config:</strong>  See parameter <code>emr_config</code>\nin <code>udeml.settings.deploy.run_remote_job</code>.</li>\n<li><strong>env:</strong>  See parameter <code>env</code>\nin <code>udeml.settings.deploy.run_remote_job</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary or a list of dictionaries of EMR-style configuration\n  including \"spark-defaults\" classification. This classification\n  has properties for the environment variables.</p>\n</blockquote>\n", "signature": "(\n    emr_config: Union[dict, List[dict], NoneType],\n    env: Union[Dict[str, str], NoneType] = None\n) -> Union[dict, List[dict]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.configutils.update_emr_config_with_application_config", "modulename": "pipeline.udeml.utils.configutils", "qualname": "update_emr_config_with_application_config", "type": "function", "doc": "<p>Updates EMR-style configuration using the spark-defaults section of the\napplication configuration file.</p>\n\n<p>We do not want to override its properties if there is a \"spark-defaults\"\nclassification in the <code>emr_config</code> given to the deploy.py, that's why we set\n<code>update_if_spark_defaults_exist</code> parameter to False.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>emr_config:</strong>  See parameter <code>emr_config</code>\nin <code>udeml.settings.deploy.run_remote_job</code>.</li>\n<li><strong>application_config_path:</strong>  Path to a config file containing\nspark-defaults configuration</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary or a list of dictionaries of EMR-style configuration\n  including \"spark-defaults\" classification. Properties of this classification\n  are constituted considering the spark-defaults in the application config file.</p>\n</blockquote>\n", "signature": "(\n    emr_config: Union[dict, List[dict], NoneType],\n    application_config_path: str = None\n) -> Union[dict, List[dict]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.connutils", "modulename": "pipeline.udeml.utils.connutils", "type": "module", "doc": "<p>Utilities for connection</p>\n"}, {"fullname": "pipeline.udeml.utils.connutils.get_spark_sql_as_df", "modulename": "pipeline.udeml.utils.connutils", "qualname": "get_spark_sql_as_df", "type": "function", "doc": "<p>Run sql query on spark and return result as pandas DataFrame.</p>\n\n<p>This function will run the SQL query on spark via Livy server and save the result on\ns3 in parquet format. It will then read out the table using <code>pandas.read_parquet()</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>query:</strong>  SQL query to run on spark.</li>\n<li><strong>s3_bucket:</strong>  Bucket to store temporary spark result (defaults to\n'udemy-dev-datasets' for dev and \"udemy-datasets\" for prod).</li>\n<li><strong>database:</strong>  Name of database (defaults to <code>tmp</code>).</li>\n<li><strong>table_name:</strong>  Name of the temporary table to store the data (defaults to None and\nwill use <code>temp_read_sql_YY_mm_dd_HH_MM_SS_ffffff</code> where the last bit is the\ncurrent time).</li>\n<li><strong>session_kwargs:</strong>  keyword arguments that are accepted by <code>LivySession.create()</code>.\nHere are some useful ones:\n<ul>\n<li><code>jars</code> (List[str]): URLs of jars to be used in this session</li>\n<li><code>py_files</code> (List[str]): URLs of Python files to be used in this session.</li>\n<li><code>files</code> (List[str]): URLs of files to be used in this session.</li>\n<li><code>driver_memory</code> (str): Amount of memory to use for the driver process\n(e.g. '512m')</li>\n<li><code>driver_cores</code> (int): Number of cores to use for the driver process.</li>\n<li><code>executor_memory</code> (str): Amount of memory to use per executor process\n(e.g. '512m').</li>\n<li><code>executor_cores</code> (int): Number of cores to use for each executor.</li>\n<li><code>num_executors</code> int): Number of executors to launch for this session.</li>\n<li><code>archives</code> (List[str]): URLs of archives to be used in this session.</li>\n<li><code>queue</code> (str): The name of the YARN queue to which submitted.</li>\n<li><code>name</code> (str): The name of this session.</li>\n<li><code>spark_conf</code> (Dict[str, Any]): Spark configuration properties.</li>\n<li><code>heartbeat_timeout</code> (int): Optional Timeout in seconds to which session be\nautomatically orphaned if no heartbeat is received.</li>\n<li><code>echo</code> (bool): Whether to echo output printed in the remote session.\nDefaults to <code>True</code>.</li>\n<li><code>check</code> (bool): Whether to raise an exception when a statement in the\nremote session fails. Defaults to <code>True</code>.</li>\n</ul></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>pandas DataFrame holding the results.</p>\n</blockquote>\n", "signature": "(\n    query: str,\n    s3_bucket: str = 'udemy-dev-datasets',\n    database: str = 'tmp',\n    table_name: Union[str, NoneType] = None,\n    session_kwargs: Union[Dict[str, str], NoneType] = None\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.connutils.remove_new_lines_in_query", "modulename": "pipeline.udeml.utils.connutils", "qualname": "remove_new_lines_in_query", "type": "function", "doc": "<p>Removes new line characters from a sql query except that\n    it does not update the substrings in quotes.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>query:</strong>  Input SQL query to be cleaned</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A query string which is cleaned from new line characters</p>\n</blockquote>\n", "signature": "(query: str) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.etlutils", "modulename": "pipeline.udeml.utils.etlutils", "type": "module", "doc": "<p>Utilities for etl</p>\n"}, {"fullname": "pipeline.udeml.utils.etlutils.execute_query", "modulename": "pipeline.udeml.utils.etlutils", "qualname": "execute_query", "type": "function", "doc": "<p>Executes the SQL query and returns the results in a dataframe.</p>\n\n<p>It retries three time in case of a failure after a wait time of two mins.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>query:</strong>  SQL Query to execute.</li>\n<li><strong>logger:</strong>  Logger object to print info logs if needed.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Dataframe with the results from sql.</p>\n</blockquote>\n", "signature": "(\n    query: str,\n    logger: Union[logging.Logger, NoneType] = None\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.etlutils.format_dates_for_presto", "modulename": "pipeline.udeml.utils.etlutils", "qualname": "format_dates_for_presto", "type": "function", "doc": "<p></p>\n", "signature": "(datelist: List[str]) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.evalutils", "modulename": "pipeline.udeml.utils.evalutils", "type": "module", "doc": "<p>Convenience utilities for evaluation.</p>\n"}, {"fullname": "pipeline.udeml.utils.evalutils.get_hl_stat", "modulename": "pipeline.udeml.utils.evalutils", "qualname": "get_hl_stat", "type": "function", "doc": "<p>Compute the Hosmer-Lemeshow test statistic on the predictions.</p>\n\n<p>The HL test measures the goodness of a fit.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>preds_df:</strong>  Dataframe with prediction probabilities and the target variable.</li>\n<li><strong>y_col:</strong>  Column name of the target variable.</li>\n<li><strong>pred_col:</strong>  Name of the column containing prediction probabilities.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>HL test statistic</p>\n</blockquote>\n", "signature": "(\n    preds_df: pandas.core.frame.DataFrame,\n    y_col: str,\n    pred_col: str\n) -> List[float]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.evalutils.get_classification_metrics", "modulename": "pipeline.udeml.utils.evalutils", "qualname": "get_classification_metrics", "type": "function", "doc": "<p>Computes classification metrics on the given prediction data.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>y:</strong>  Array containing target variable data (0s and 1s).</li>\n<li><strong>y_pred_prob:</strong>  Array containing prediction probabilities.</li>\n<li><strong>threshold:</strong>  Minimum probability threshold to convert prediction probabilities.\nto final predictions(0/1). By default, it is set to 0.5</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Dictionary containing auc, f1_score, accuracy, precision, recall,\n    and brier score.</p>\n</blockquote>\n", "signature": "(\n    y: <built-in function array>,\n    y_pred_prob: <built-in function array>,\n    threshold: float = 0.5\n) -> Dict[str, float]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.evalutils.get_regression_metrics", "modulename": "pipeline.udeml.utils.evalutils", "qualname": "get_regression_metrics", "type": "function", "doc": "<p>Computes regression metrics on the given prediction data.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>y:</strong>  Array containing target variable data (0s and 1s).</li>\n<li><strong>y_pred:</strong>  Array containing prediction values.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Dictionary containing mse, rmse, r2, mae, and mape.</p>\n</blockquote>\n", "signature": "(\n    y: <built-in function array>,\n    y_pred: <built-in function array>\n) -> Dict[str, float]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils", "modulename": "pipeline.udeml.utils.formatutils", "type": "module", "doc": "<p>Utilities useful for for displaying numbers, datetime, timedelta, etc.</p>\n"}, {"fullname": "pipeline.udeml.utils.formatutils.guess_timestamp_unit", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "guess_timestamp_unit", "type": "function", "doc": "<p></p>\n", "signature": "(ts: int) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_get_datetime", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_get_datetime", "type": "function", "doc": "<p></p>\n", "signature": "(\n    x: Any,\n    unit: Union[str, NoneType] = None,\n    err_handler: Union[Callable, NoneType] = None\n) -> Union[pandas._libs.tslibs.timestamps.Timestamp, NoneType]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_datetime", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_datetime", "type": "function", "doc": "<p></p>\n", "signature": "(\n    x: Any,\n    unit: Union[str, NoneType] = None,\n    err_handler: Union[Callable, NoneType] = None\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_get_timedelta", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_get_timedelta", "type": "function", "doc": "<p></p>\n", "signature": "(\n    x: Any,\n    unit: str = 'ms',\n    err_handler: Union[Callable, NoneType] = None\n) -> Union[pandas._libs.tslibs.timedeltas.Timedelta, NoneType]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_timedelta", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_timedelta", "type": "function", "doc": "<p></p>\n", "signature": "(\n    x: Any,\n    unit: Union[str, NoneType] = None,\n    max_unit: str = 'd',\n    full_precision: bool = True,\n    round_td: Union[str, pandas._libs.tslibs.timedeltas.Timedelta, NoneType] = None,\n    err_handler: Union[Callable, NoneType] = None\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_num", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_num", "type": "function", "doc": "<p>Format a numeric value by rounding it appropriately based on its magnitude.</p>\n", "signature": "(\n    x: Any,\n    full_precision: bool = True,\n    err_handler: Union[Callable, NoneType] = None\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_ccy", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_ccy", "type": "function", "doc": "<p>Format a currency value by rounding it appropriately based on its magnitude.</p>\n", "signature": "(\n    x: Any,\n    ccy_sign: str = '$',\n    err_handler: Union[Callable, NoneType] = None,\n    full_precision: bool = True\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_interval_from_start_end_timestamps", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_interval_from_start_end_timestamps", "type": "function", "doc": "<p></p>\n", "signature": "(\n    start_timestamp: Any,\n    end_timestamp: Any,\n    unit: Union[str, NoneType] = None,\n    full_precision: bool = False\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.formatutils.try_fmt_timedeltas_from_interval_str", "modulename": "pipeline.udeml.utils.formatutils", "qualname": "try_fmt_timedeltas_from_interval_str", "type": "function", "doc": "<p></p>\n", "signature": "(bin_name)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.gitutils", "modulename": "pipeline.udeml.utils.gitutils", "type": "module", "doc": "<p>Utilities for interacting with git source control.</p>\n"}, {"fullname": "pipeline.udeml.utils.gitutils.get_git_hash", "modulename": "pipeline.udeml.utils.gitutils", "qualname": "get_git_hash", "type": "function", "doc": "<p>Get hash of current git revision.</p>\n", "signature": "() -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.gitutils.get_git_user_name", "modulename": "pipeline.udeml.utils.gitutils", "qualname": "get_git_user_name", "type": "function", "doc": "<p>Get git user.name from the config</p>\n", "signature": "() -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.gitutils.get_user_name", "modulename": "pipeline.udeml.utils.gitutils", "qualname": "get_user_name", "type": "function", "doc": "<p>Gets the username by using the git credentials</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Username string</p>\n</blockquote>\n", "signature": "() -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.inpututils", "modulename": "pipeline.udeml.utils.inpututils", "type": "module", "doc": "<p>Utilities related to getting and validating user input.</p>\n\n<p>NOTE(sam): This module is imported from <code>../settings/deploy.py</code> which needs to run\nwith a small subset of requirements which are defined in\n<code>../deploy_requirements.txt</code>, so if you add new imports, make sure they are added to\nthat file as well.</p>\n"}, {"fullname": "pipeline.udeml.utils.inpututils.get_input", "modulename": "pipeline.udeml.utils.inpututils", "qualname": "get_input", "type": "function", "doc": "<p>Get user input with typing and validation</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>prompt:</strong>  prompt string so user know what input is expected.</li>\n<li><strong>validator:</strong>  If a Callable, the (optionally typed) input would be passed to it\nand would expect boolean output of whether the input is valid. If\nIterable, then will check if input exists in the collection. If string,\nthen it would be used as a regular expression to which the input must\nconform to.</li>\n<li><strong>forced_type:</strong>  if provided, would pass input to it to force the type. (e.g. int\nto force input to be integer) (default: None)</li>\n<li><strong>validation_failed_msg:</strong>  Override the default message when validation fails.\n(default: None and will have a reasonable message depending on validator\ntype)</li>\n<li><strong>quit_keyword:</strong>  keyword to use to quit the input process (defaults to 'quit()')</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The validated result.</p>\n</blockquote>\n", "signature": "(\n    prompt: str,\n    validator: Union[Callable[[Any], bool], Iterable, str],\n    forced_type: Union[type, NoneType] = None,\n    validation_failed_msg: Union[str, NoneType] = None,\n    quit_keyword: str = 'quit()'\n) -> Any", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.jobutils", "modulename": "pipeline.udeml.utils.jobutils", "type": "module", "doc": "<p>Utilities for multi-processing and multi-threading</p>\n"}, {"fullname": "pipeline.udeml.utils.jobutils.parallel_map", "modulename": "pipeline.udeml.utils.jobutils", "qualname": "parallel_map", "type": "function", "doc": "<p>Apply a function to a list of inputs in a pool of jobs.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>func:</strong>  Function which accepts keyword arguments.</li>\n<li><strong>kwargs_list:</strong>  List of kwargs used to call <code>func</code>.</li>\n<li><strong>n_jobs:</strong>  Pool size.</li>\n<li><strong>backend:</strong>  <code>backend</code> used by joblib (default: 'loky')\nPick from {'threading', 'multiprocessing', 'loky'}</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of results from calling func with each input.</p>\n</blockquote>\n", "signature": "(\n    func: Callable[[Any], Any],\n    kwargs_list: List[Dict[str, Any]],\n    n_jobs: int = -1,\n    backend: str = 'loky'\n) -> List[Any]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.logutils", "modulename": "pipeline.udeml.utils.logutils", "type": "module", "doc": "<p>Utilities for logging</p>\n"}, {"fullname": "pipeline.udeml.utils.logutils.setup_logger", "modulename": "pipeline.udeml.utils.logutils", "qualname": "setup_logger", "type": "function", "doc": "<p>Set up a logger which optionally also logs to file.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>logger_name:</strong>  name of logger. Note that if you set up a logger\nwith a previously used name, you will simply change properties of\nthe existing logger, so be careful!</li>\n<li><strong>file_name:</strong>  name of logging file. If nothing provided, will not\nlog to file</li>\n<li><strong>log_to_std_out:</strong>  whether the log should be output to stdout\n(default: True)</li>\n<li><strong>log_level:</strong>  log levels from logging library (default:\n<code>logging.DEBUG</code>)</li>\n<li><strong>base_dir:</strong>  directory of where to put the log file (default:\n\"./log\")</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>logger object.</p>\n</blockquote>\n", "signature": "(\n    logger_name: str,\n    file_name: Union[str, NoneType] = None,\n    log_to_stdout: bool = True,\n    log_level: int = 10,\n    base_dir: str = './logs'\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.logutils.set_all_logger_levels", "modulename": "pipeline.udeml.utils.logutils", "qualname": "set_all_logger_levels", "type": "function", "doc": "<p>Change logging level for all named loggers.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>log_level:</strong>  integer log level from <code>logging</code> module. positive values mean\nlog level should be at least as aggressive and negative values mean\nlog level should be at least as conservative.</li>\n<li><strong>inc_regex:</strong>  regular expression to apply as include filter for logger name.</li>\n<li><strong>exc_regex:</strong>  regular expression to apply as exclude filter for logger name.</li>\n</ul>\n", "signature": "(\n    log_level: int,\n    inc_regex: Union[str, NoneType] = None,\n    exc_regex: Union[str, NoneType] = None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils", "modulename": "pipeline.udeml.utils.miscutils", "type": "module", "doc": "<p>Miscellaneous utilities that do not fit nicely within other utils.</p>\n"}, {"fullname": "pipeline.udeml.utils.miscutils.get_callable_kwargs", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "get_callable_kwargs", "type": "function", "doc": "<p>Get list of arguments for a callable.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>func:</strong>  A Callable object like a function or a class</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of argument names accepted by the callable.</p>\n</blockquote>\n", "signature": "(func: Callable) -> List[str]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.filter_unsupported_kwargs", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "filter_unsupported_kwargs", "type": "function", "doc": "<p>Decorateor for filtering out kwargs which are not supported.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>logger:</strong>  A callable that takes a string and logs it. In this case, it will\nonly be used to warn about any kwargs that will be filtered out due to\nnot being supported by the wrapped function.</li>\n</ul>\n", "signature": "(logger: Union[Callable, NoneType] = None)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.reload_module", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "reload_module", "type": "function", "doc": "<p></p>\n", "signature": "(module_name)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.time_me", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "time_me", "type": "function", "doc": "<p></p>\n", "signature": "(func, *args, **kwargs)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.retry", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "retry", "type": "function", "doc": "<p>Decorator for allowing a function to retry</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>max_tries:</strong>  Maximum number of attempts to call the function. (default: 1)</li>\n<li><strong>wait_secs:</strong>  time to wait between failures in seconds. (default: 5)</li>\n<li><strong>raise_on_fail:</strong>  Whether to raise if all attempts fail (default: True)</li>\n<li><strong>res_on_fail:</strong>  value to return in case of failure (default: None). Obviously,\nthis only makes sense when raise_on_fail is set to False.</li>\n</ul>\n", "signature": "(\n    max_tries: int = 3,\n    wait_secs: int = 5,\n    raise_on_fail: bool = True,\n    res_on_fail: Any = None\n) -> Any", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.diff_rec", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "diff_rec", "type": "function", "doc": "<p>Returns diff of two dictionaries (or non-string iterables).\nIt uses recursive drill down, so do not use on structures which have big depth!</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>left:</strong>  left dict or non-string iterable</li>\n<li><strong>right:</strong>  right dict or non-string iterable</li>\n<li><strong>ignore_keys:</strong>  optional set of keys to be ignored during comparison</li>\n<li><strong>comp_mode:</strong>  Numerical comparison modes. Must be one of\n<ul>\n<li>sf : significant figures</li>\n<li>dp : decimal places</li>\n<li>pc : percentage change</li>\n</ul></li>\n<li><strong>precision:</strong>  precision depending on the mode:\nif comp_mode='sf' then significant figures to round to before comparison\nif comp_mode='dp' then decimal places to round to before comparison\nif comp_mode='pc' then percentage change required to trigger diff</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>diff of left and right. If left and right were dictionaries that are not\n  identical, then one or more of the following keys will exist:\n      - \"ValDiff\": if there are keys which have value differences, then this\n          will contain a dictionary of those keys with values being tuple of\n          (left_value, right_value, diff_value) if numerical or simply\n          (left_value, right_value) if not numerical.\n      - \"OnlyInLeft\": if there are some keys that only exist in the left, then\n          those keys and their values will appear here.\n      - \"OnlyInLeft\": if there are some keys that only exist in the right, then\n          those keys and their values will appear here.</p>\n</blockquote>\n", "signature": "(\n    left: Union[dict, Iterable],\n    right: Union[dict, Iterable],\n    ignore_keys: Union[set, NoneType] = None,\n    comp_mode: str = 'dp',\n    precision: int = 6\n) -> Union[Dict, Tuple]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.isfloat", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "isfloat", "type": "function", "doc": "<p>Determines whether given string is convertable to float or not.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>x:</strong>  input string to be checked</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the string is convertable to float, False otherwise.</p>\n</blockquote>\n", "signature": "(x: str)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.isint", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "isint", "type": "function", "doc": "<p>Determines whether given string is convertable to integer or not.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>x:</strong>  input string to be checked</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the string is convertable to int, False otherwise.</p>\n</blockquote>\n", "signature": "(x: str)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.miscutils.convert_args_list_to_dict", "modulename": "pipeline.udeml.utils.miscutils", "qualname": "convert_args_list_to_dict", "type": "function", "doc": "<p>Converts given arguments lists to a dictionary of argument name\nand value pairs.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>args_list:</strong>  A list containing of script arguments.</li>\n<li>It does not support boolean flags. All arguments names should start with \"--\"</li>\n<li>and should be followed by the argument value.</li>\n<li>e.g. ['--test_value', 'A', '--num', '10']</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary of argument name and value pairs.</p>\n</blockquote>\n", "signature": "(args_list: List[str]) -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.pdutils", "modulename": "pipeline.udeml.utils.pdutils", "type": "module", "doc": "<p>Utilities for pandas objects.</p>\n"}, {"fullname": "pipeline.udeml.utils.pdutils.apply_func_to_df_parts", "modulename": "pipeline.udeml.utils.pdutils", "qualname": "apply_func_to_df_parts", "type": "function", "doc": "<p>Apply a function to parts of DataFrame in separate processes.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>func:</strong>  A function which supports at least the following kwargs:\n<code>df</code> (pd.DataFrame): part of original DataFrame\n<code>i</code> (int): index of the dataframe part\n<code>start_idx</code> (int): start index from original DataFrame\n<code>end_idx</code> (int): end index from original DataFrame\nThe function must also have as kwargs anything passed by\nthe <code>ctx</code> argument.</li>\n<li><strong>df:</strong>  DataFrame you want to apply function to in parallel.</li>\n<li><strong>parts:</strong>  Number of parts to divide the dataframe into.</li>\n<li><strong>n_jobs:</strong>  Number of parallelization jobs. (default: None\nand will default to minimum of half the CPUs or the\nnumber of requested parts.)</li>\n<li><strong>ctx:</strong>  An optional context dictionary containing additional\nkeys and values to pass to the <code>func</code> for each part.\n(default: None)</li>\n<li><strong>backend:</strong>  Backend to use for joblib (default: 'loky')\nPick from {'threading', 'multiprocessing', 'loky'}</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of results from application of function to DataFrame parts.</p>\n</blockquote>\n", "signature": "(\n    func: Callable[[dict], Any],\n    df: pandas.core.frame.DataFrame,\n    parts: int,\n    n_jobs: Union[int, NoneType] = None,\n    ctx: Union[dict, NoneType] = None,\n    backend: str = 'loky'\n) -> List[Any]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils", "modulename": "pipeline.udeml.utils.persistutils", "type": "module", "doc": "<p>Utilities related to persisting data to file storage.</p>\n\n<p>NOTE(sam): This module is imported from <code>../settings/deploy.py</code> which needs to run\nwith a small subset of requirements which are defined in\n<code>../deploy_requirements.txt</code>, so if you add new imports, make sure they are added to\nthat file as well.</p>\n"}, {"fullname": "pipeline.udeml.utils.persistutils.ensure_dirs", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "ensure_dirs", "type": "function", "doc": "<p>Create directories if they do not exist.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>dir_name:</strong>  Directory name on local machine.</li>\n<li><strong>silent:</strong>  Whether to suppress printing info message. (Defaults to False)</li>\n<li><strong>raise_on_error:</strong>  Whether to raise exception on any errors. (Defaults to True)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the dir_name exists.</p>\n</blockquote>\n", "signature": "(\n    dir_name: str,\n    silent: bool = False,\n    raise_on_error: bool = True\n) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.dump_local", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "dump_local", "type": "function", "doc": "<p>Save a python object to local drive in joblib or json format.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>obj:</strong>  Arbitrary serializable python object.</li>\n<li><strong>path:</strong>  Path on local machine to store the object.</li>\n<li><strong>dump_format:</strong>  format of the saved file. Currently support {'dill', 'joblib',\n'json'}. (Defaults to 'joblib')</li>\n<li><strong>create_dirs:</strong>  Whether the path directory should be created. (Defaults to True)</li>\n<li><strong>silent:</strong>  Whether to suppress printing info message. (Defaults to False)</li>\n<li><strong>raise_on_error:</strong>  Whether to raise exception on any errors. (Defaults to True)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the file was successfully saved.</p>\n</blockquote>\n", "signature": "(\n    obj: Any,\n    path: str,\n    dump_format: str = 'joblib',\n    create_dirs=True,\n    silent: bool = False,\n    raise_on_error: bool = True\n) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.decompose_s3_path", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "decompose_s3_path", "type": "function", "doc": "<p>Get bucket and key from full s3 path.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Tuple of bucket and key.</p>\n</blockquote>\n", "signature": "(s3_path: str) -> Tuple[str, str]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.upload_file_to_s3", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "upload_file_to_s3", "type": "function", "doc": "<p>Upload a file from local machine to s3.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>local_path:</strong>  Path on local machine.</li>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n<li><strong>silent:</strong>  Whether to suppress printing info message. (Defaults to False)</li>\n<li><strong>raise_on_error:</strong>  Whether to raise exception on any errors. (Defaults to True)</li>\n<li><strong>boto3_kwargs:</strong>  The parameters for s3.meta.client.upload_file() function.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the file was successfully uploaded.</p>\n</blockquote>\n", "signature": "(\n    local_path: str,\n    s3_path: str,\n    silent: bool = False,\n    raise_on_error: bool = True,\n    boto3_kwargs: Union[Dict[str, Union[str, float]], NoneType] = None\n) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.download_file_from_s3", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "download_file_from_s3", "type": "function", "doc": "<p>Download a file from s3 to local machine.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n<li><strong>local_path:</strong>  Path on local machine.</li>\n<li><strong>create_dirs:</strong>  Whether the path directory should be created. (Defaults to True)</li>\n<li><strong>silent:</strong>  Whether to print debug information.</li>\n<li><strong>raise_on_error:</strong>  Whether to raise exception on any errors. (Defaults to True)</li>\n<li><strong>boto3_kwargs:</strong>  The parameters for s3.meta.client.download_fileobj() function.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the file was successfully downloaded.</p>\n</blockquote>\n", "signature": "(\n    s3_path: str,\n    local_path: str,\n    create_dirs: bool = True,\n    silent: bool = False,\n    raise_on_error: bool = True,\n    boto3_kwargs: Union[Dict[str, Union[str, float]], NoneType] = None\n) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.exists_in_s3", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "exists_in_s3", "type": "function", "doc": "<p>Check whether a fully specified s3 path exists.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the file exists on s3 (None if there was an error.)</p>\n</blockquote>\n", "signature": "(s3_path: str) -> Union[bool, NoneType]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.delete_from_s3", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "delete_from_s3", "type": "function", "doc": "<p>Delete a path from s3</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Boolean of whether the delete was successful.</p>\n</blockquote>\n", "signature": "(s3_path: str) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.persistutils.list_s3_keys", "modulename": "pipeline.udeml.utils.persistutils", "qualname": "list_s3_keys", "type": "function", "doc": "<p>List s3 object under a particular path.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>s3_path:</strong>  Full path on s3 in format \"s3://<bucket_name>/<obj_path>\".</li>\n<li><strong>inc_regex:</strong>  regular expression to apply as include filter to fetched keys.</li>\n<li><strong>exc_regex:</strong>  regular expression to apply as exclude filter to fetched keys.</li>\n<li><strong>fld_regex:</strong>  regular expression for matching fields to show for each object.\n(Defaults to None and would only list the keys)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of s3 object information tuples or dictionaries.</p>\n</blockquote>\n", "signature": "(\n    s3_path: str,\n    inc_regex: Union[str, NoneType] = None,\n    exc_regex: Union[str, NoneType] = None,\n    fld_regex: Union[str, NoneType] = None\n) -> Union[List[Dict[str, Any]], List[Tuple[Any]]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sagemakerutils", "modulename": "pipeline.udeml.utils.sagemakerutils", "type": "module", "doc": "<p>Utilities for sagemaker</p>\n"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus", "type": "class", "doc": "<p>An enumeration.</p>\n", "bases": "enum.Enum"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus.InProgress", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus.InProgress", "type": "variable", "doc": "<p></p>\n", "default_value": " = <JobStatus.InProgress: 'InProgress'>"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus.Completed", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus.Completed", "type": "variable", "doc": "<p></p>\n", "default_value": " = <JobStatus.Completed: 'Completed'>"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus.Failed", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus.Failed", "type": "variable", "doc": "<p></p>\n", "default_value": " = <JobStatus.Failed: 'Failed'>"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus.Stopping", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus.Stopping", "type": "variable", "doc": "<p></p>\n", "default_value": " = <JobStatus.Stopping: 'Stopping'>"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.JobStatus.Stopped", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "JobStatus.Stopped", "type": "variable", "doc": "<p></p>\n", "default_value": " = <JobStatus.Stopped: 'Stopped'>"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.get_job_statuses", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "get_job_statuses", "type": "function", "doc": "<p>Gets the status of the jobs which are created by the given user.\nIf username is not given, the current username is retrieved using\ngit credentials.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>status_list:</strong>  List of status to filter the processing jobs</li>\n<li><strong>user_name:</strong>  Username to search their jobs</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary containing name of the jobs created by the searched user\n  as the key and the status of that job as the value.</p>\n</blockquote>\n", "signature": "(\n    user_name: str = None,\n    status_list: Union[List[str], NoneType] = None\n) -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.get_incomplete_jobs_count", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "get_incomplete_jobs_count", "type": "function", "doc": "<p>Gets the number of the incomplete jobs created by the current user.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The number of incomplete jobs</p>\n</blockquote>\n", "signature": "() -> int", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sagemakerutils.stop_running_jobs", "modulename": "pipeline.udeml.utils.sagemakerutils", "qualname": "stop_running_jobs", "type": "function", "doc": "<p>Stop the given job or all running jobs created by the current user\nafter asking the user's approval.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>job_name:</strong>  The job name to be stopped</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>boolean value indicating whether any job is stopped or not.</p>\n</blockquote>\n", "signature": "(job_name: str = None) -> bool", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.searchutils", "modulename": "pipeline.udeml.utils.searchutils", "type": "module", "doc": "<p>Udemy Custom Search API Library</p>\n\n<p>For detailed explanation of Custom Search API and parameters:\nhttps://udemywiki.atlassian.net/wiki/spaces/PDEUX/pages/1173586543/Custom+Search+API</p>\n"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI", "type": "class", "doc": "<p>Collects search results from Custom Search API.</p>\n\n<p>Custom Search API is only for internal use.\nBearer token is needed for authentication.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>bearer (str):</strong>  String representation of user's bearer token.</li>\n</ul>\n"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.__init__", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, bearer: str)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.URL", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.URL", "type": "variable", "doc": "<p></p>\n", "default_value": " = 'https://www.udemy.com/api-2.0/search-courses/first-phase/custom'"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.CUSTOM_API_PARAM_MAP", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.CUSTOM_API_PARAM_MAP", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'query': 'q', 'ranking_enabled': 'ranking', 'layering_enabled': 'layering', 'query_analyzing_enabled': 'query_analyzing', 'curriculum_search_enabled': 'curriculum_search', 'debug_enabled': 'debug'}"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.SEGMENT_TYPE_MAP", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.SEGMENT_TYPE_MAP", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'filter': 'filter_segment', 'filter_and_ranking': 'filter_and_ranking_segment'}"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.VALID_KWARGS", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.VALID_KWARGS", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'ranking_enabled', 'debug_enabled', 'query_analyzing_enabled', 'layering_enabled', 'curriculum_search_enabled', 'segment_type', 'pmml_model', 'page_size', 'course_ids', 'query_size', 'segment_enabled', 'locale', 'query'}"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.DEFAULT_COURSE_LIMIT_FOR_THREADING", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.DEFAULT_COURSE_LIMIT_FOR_THREADING", "type": "variable", "doc": "<p></p>\n", "default_value": " = 250"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.DEFAULT_NUM_THREADS", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.DEFAULT_NUM_THREADS", "type": "variable", "doc": "<p></p>\n", "default_value": " = 4"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.get_response_from_api", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.get_response_from_api", "type": "function", "doc": "<p>Calls custom search API with some pre and post checks.</p>\n\n<p>Custom API supports POST requests rather than GET requests.\nIf <code>_num_threads</code> is provided, or  course_ids list is greater than\n<code>_course_limit_for_threading</code>, will call the API with multi-threading.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>_as_object (bool):</strong>  Whether result should be returned as a SimpleNamespace\ninstead of the default json (defaults to False).</li>\n<li><strong>_num_threads (int):</strong>  number of threads to call the API in (defaults to\n<code>DEFAULT_NUM_THREADS</code> if course_ids is greater than\n<code>_course_limit_for_threading</code>).</li>\n<li><strong>_course_limit_for_threading (int):</strong>  maximum number of courses before\nthreading would be used (defaults to\n<code>DEFAULT_COURSE_LIMIT_FOR_THREADING</code> but is ignored if <code>_num_threads</code>\nis provided).</li>\n<li><strong>query (str):</strong>  query keyword</li>\n<li><strong>ranking_enabled (bool):</strong>  apply ranking by MEE (defaults to True)</li>\n<li><strong>layering_enabled (bool):</strong>  apply final layering, which includes\nboosts for paid, user locale, and match and curriculum phrase match\n(defaults to True)</li>\n<li><strong>query_analyzing_enabled (bool):</strong>  analyzes the query with\nQuery Understanding service\n(defaults to True)</li>\n<li><strong>curriculum_search_enabled (bool):</strong>  executes curriculum search\n(defaults to True)</li>\n<li><strong>debug_enabled (bool):</strong>  shows feature values sent to MEE for final score\ncalculation and also matches that courses get\n(such as \u201cand_match\u201d, \u201cphrase_match_headline_t\u201d etc.)\n(defaults to False)</li>\n<li><strong>segment_enabled (bool):</strong>  enables/disables segmentation logic\n(defaults to False)</li>\n<li><strong>segment_type (str):</strong>  segment type used only if segment_enabled is True,\nchoices: ['filter', 'filter_and_ranking']</li>\n<li><strong>page_size (int):</strong>  number of course results\n(defaults to 20 and supports up to 10000)</li>\n<li><strong>query_size (int):</strong>  number of courses sent to ES for scoring\n(defaults to 360 and supports up to 10000)</li>\n<li><strong>pmml_model (str):</strong>  choose PMML model\n(defaults to model used in production\n'mx_vib_pct_months_with_content_update')</li>\n<li><strong>course_ids (list of str):</strong>  a comma separated list of course ids\nto be included\n(defaults to empty)</li>\n<li><strong>locale (str):</strong>  user locale (defaults to last locale set)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>API response as JSON or SimpleNameSpace</p>\n</blockquote>\n", "signature": "(\n    self,\n    **kwargs\n) -> Union[Dict[str, Union[float, int, List]], types.SimpleNamespace, NoneType]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.searchutils.CustomSearchAPI.get_fields_from_json_response", "modulename": "pipeline.udeml.utils.searchutils", "qualname": "CustomSearchAPI.get_fields_from_json_response", "type": "function", "doc": "<p>Returns only specified fields for each course from the API JSON response.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>json_response:</strong>  API response as JSON</li>\n<li><strong>fields:</strong>  Fields to be returned from API response.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of specified fields for each course.</p>\n</blockquote>\n\n<p>Example:\n[{'title': 'Machine Learning A-Z\u2122: Hands-On Python &amp; R In Data Science',\n  'headline': 'Learn to create Machine Learning Algorithms in Python\n  and R from two Data Science experts.',\n  'id': 950390},\n {'title': 'Complete Machine Learning &amp; Data Science Bootcamp 2021',\n  'headline': 'Learn Data Science, Data Analysis, Machine Learning\n  (Artificial Intelligence) and Python with Tensorflow',\n  'id': 2511476}]</p>\n", "signature": "(\n    self,\n    json_response: Dict[str, Union[float, int, List]],\n    fields: List[str]\n) -> Union[List[Dict[str, Any]], NoneType]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.shellutils", "modulename": "pipeline.udeml.utils.shellutils", "type": "module", "doc": "<p>Module containing shell utilities.</p>\n"}, {"fullname": "pipeline.udeml.utils.shellutils.run_cmd", "modulename": "pipeline.udeml.utils.shellutils", "qualname": "run_cmd", "type": "function", "doc": "<p>Run an arbitrary shell command and optionally store its output to a log file.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>cmd_list:</strong>  Arbitrary shell command. e.g. \"rsync -av from_path to_path\"\nwould have to be passed as [\"rsync\", \"-av\", \"from_path\", \"to_path\"]</li>\n<li><strong>log_path:</strong>  Optionally provided path to a file to store the stdout.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Integer return code from running the command.</p>\n</blockquote>\n", "signature": "(cmd_list: List[str], log_path: Union[str, NoneType] = None) -> int", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.shellutils.run_cmd_await", "modulename": "pipeline.udeml.utils.shellutils", "qualname": "run_cmd_await", "type": "function", "doc": "<p>Run a shell command and wait for process to terminate.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>cmd:</strong>  Shell command as string. e.g. \"rsync -av from_path to_path\"</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A tuple that contains integer return code, stdout and stderr\n  from running the command.</p>\n</blockquote>\n", "signature": "(cmd: str) -> Tuple[int, IO[~AnyStr], IO[~AnyStr]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.shellutils.rsync", "modulename": "pipeline.udeml.utils.shellutils", "qualname": "rsync", "type": "function", "doc": "<p>Wrapper for rsync command.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>src:</strong>  Path to the source directory.</li>\n<li><strong>dest:</strong>  Path to the destination directory.</li>\n<li><strong>options:</strong>  List of rsync command options.\n(Defaults to -a -v to increase verbosity of the transfer)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Exit code of the command.</p>\n</blockquote>\n", "signature": "(\n    src: str,\n    dest: str,\n    options: Union[List[str], NoneType] = None\n) -> int", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.shellutils.remove_dir_contents", "modulename": "pipeline.udeml.utils.shellutils", "qualname": "remove_dir_contents", "type": "function", "doc": "<p>Remove contents of a directory without deleting the directory itself.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>directory:</strong>  Path of directory to remove contents from.</li>\n<li><strong>exclude_pattern:</strong>  Regular expression of files not to remove.</li>\n</ul>\n", "signature": "(directory: str, exclude_pattern: Union[str, NoneType] = None)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils", "modulename": "pipeline.udeml.utils.sklutils", "type": "module", "doc": "<p>Convenience utilities for sklearn and preprocessing.</p>\n"}, {"fullname": "pipeline.udeml.utils.sklutils.force_dt_cols", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "force_dt_cols", "type": "function", "doc": "<p>Given a DataFrame and list of date columns, enforce date type.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  Input DataFrame.</li>\n<li><strong>dt_cols:</strong>  List of column names known to be date columns.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Same as input dataframe (i.e. has side-effect).</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    dt_cols: List[str]\n) -> pandas.core.frame.DataFrame", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.get_col_types", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "get_col_types", "type": "function", "doc": "<p>Given a DataFrame return dictionary of types to column list.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  Input DataFrame</li>\n<li><strong>known_num_cols:</strong>  List of known numeric columns. If provided column\nwill not be checked.</li>\n<li><strong>known_ctg_cols:</strong>  List of known categorical columns. If provided column\nwill not be checked.</li>\n<li><strong>known_num_cols:</strong>  List of known datetime columns. If provided column\nwill not be checked.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Dictionary mapping from a string which represents a type to a list\n  of fields that have that type. Currently supports following types:\n  {\"num\", \"ctg\", \"dt\"}.</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    known_num_cols: Union[List[str], NoneType] = None,\n    known_ctg_cols: Union[List[str], NoneType] = None,\n    known_dt_cols: Union[List[str], NoneType] = None\n) -> Dict[str, List[str]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.make_generic_preproc", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "make_generic_preproc", "type": "function", "doc": "<p>Given a DataFrame and its columns, return a ColumnTransformer for\npreprocessing.</p>\n\n<p>The function will figure out field types and then set up a ColumnTransformer\nwhich would apply a median Imputer and StandardsScaler to numeric values and\n<NULL> Imputer and OneHotEncoder to categorical values.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  input DataFrame</li>\n<li><strong>cols:</strong>  optional list of columns to target for preprocessing. If provided, any\nadditional columns in the DataFrame are simply passed through at the end.\nThis can be useful when you have a DataFrame which has both the features\nand the label data and you only want to transform the features. (default\nto None and will simply use all available columns)</li>\n<li><strong>num_preproc:</strong>  Numerical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_NUM_PREPROC</code>.</li>\n<li><strong>ctg_preproc:</strong>  Categorical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_CTG_PREPROC</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>ColumnTransformer object which can be use to <code>fit_transform()</code> the input\n  DataFrame. Note that the ColumnTransformer is not fitted.</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    cols: Union[List[str], NoneType] = None,\n    num_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    ctg_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None\n) -> sklearn.compose._column_transformer.ColumnTransformer", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.fit_transform_generic_preproc", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "fit_transform_generic_preproc", "type": "function", "doc": "<p>Given a DataFrame, apply generic preprocessing transform on it.</p>\n\n<p>This function makes use of <code>make_generic_preproc()</code> function, so check\nthe details of the transformation there.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  input DataFrame</li>\n<li><strong>cols:</strong>  optional list of columns to target for preprocessing. If provided, any\nadditional columns in the DataFrame are simply passed through at the end.\nThis can be useful when you have a DataFrame which has both the features\nand the label data and you only want to transform the features. (default\nto None and will simply use all available columns)</li>\n<li><strong>num_preproc:</strong>  Numerical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_NUM_PREPROC</code>.</li>\n<li><strong>ctg_preproc:</strong>  Categorical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_CTG_PREPROC</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Tuple containing the transformed data, the fitted ColumnTransformer, and a\n  list of all the features which were transformed. Last argument is useful if\n  you pass a subset of the columns as features).</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    cols: Union[List[str], NoneType] = None,\n    num_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    ctg_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None\n) -> Tuple[pandas.core.frame.DataFrame, sklearn.compose._column_transformer.ColumnTransformer, List[str]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.get_coltrans_cols", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "get_coltrans_cols", "type": "function", "doc": "<p>Given a ColumnTransformer, figures out the transformed output columns.</p>\n\n<p>Note that if the ColumnTransformer has <code>remainder=\"passthrough\"</code> set,\nthose will be missing from the list returned by this function.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>coltrans (ColumnTransformer):</strong>  sklearn\nColumnTransformer that has been fit.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>(List[str]) List of transformed columns</p>\n</blockquote>\n", "signature": "(\n    coltrans: sklearn.compose._column_transformer.ColumnTransformer\n) -> List[str]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.make_generic_model_pipeline", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "make_generic_model_pipeline", "type": "function", "doc": "<p>Make a generic model pipeline for structured data.</p>\n\n<p>This function is useful for making a generic sklearn model pipeline.\nGiven a DataFrame of features and target variable, the desired model\nclass and the params, it creates a generic preprocessing pipeline\nfor the data that handles numeric and categorical variables, and\ndepending on the whether the params are implying a grid-search,\nalso includes a grid-search</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  DataFrame of features (x_col) and target variable (y_col)</li>\n<li><strong>y_col:</strong>  name of prediction target column.</li>\n<li><strong>x_cols:</strong>  list of feature column names.</li>\n<li><strong>model_class:</strong>  Any classifier or regressor sklearn object.</li>\n<li><strong>params:</strong>  either a dictionary of values, or a dictionary of list\nof values. If the latter, the model pipeline will be wrapped\nin a  GridSearch.</li>\n<li><strong>cv:</strong>  <code>cv</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>scoring:</strong>  <code>scoring</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>refit:</strong>  <code>refit</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>calib_method:</strong>  provide one of {\"sigmoid\", \"isotonic\"} if you are\nusing a classifier which does not produce calibrated\nprobabilities (i.e. non-GLM methods)</li>\n<li><strong>model_n_jobs:</strong>  <code>n_jobs</code> arg for the model (defaults to -1 if supported\nby the model, otherwise will be ignored.)</li>\n<li><strong>gs_n_jobs:</strong>  <code>n_jobs</code> arg for gridsearch (defaults to -1)</li>\n<li><strong>search_type:</strong>  Type of hyperparameter search.\nOptions:\n   None   -> No Hyper parameter optimization.\n   grid   -> GridSearchCV\n   bayes  -> BayesSearchCV\n   random -> RandomizedSearchCV\nDefaults to None but will use grid search if parameters are all lists.</li>\n<li><strong>n_iter:</strong>  Number of model tuning iterations for Randomized and Bayesian search.</li>\n<li><strong>num_preproc:</strong>  Numerical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_NUM_PREPROC</code>.</li>\n<li><strong>ctg_preproc:</strong>  Categorical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_CTG_PREPROC</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Pipeline with names steps \"preproc\" and \"model\". Note that\n  the pipeline is not fitted.</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    y_col: str,\n    x_cols: List[str],\n    model_class: sklearn.base.BaseEstimator,\n    params: Union[Dict[str, Union[str, float, List[Union[str, float]]]], NoneType] = None,\n    cv: Union[int, sklearn.model_selection._split.BaseCrossValidator, Iterator, NoneType] = None,\n    scoring: Union[str, Callable, List, Tuple, Dict, NoneType] = None,\n    refit: Union[bool, str, Callable, NoneType] = None,\n    calib_method: Union[str, NoneType] = None,\n    model_n_jobs: Union[int, NoneType] = -1,\n    gs_n_jobs: Union[int, NoneType] = -1,\n    search_type: Union[str, NoneType] = None,\n    n_iter: Union[int, NoneType] = None,\n    num_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    ctg_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None\n) -> sklearn.pipeline.Pipeline", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.sklutils.fit_predict_generic_model", "modulename": "pipeline.udeml.utils.sklutils", "qualname": "fit_predict_generic_model", "type": "function", "doc": "<p>Create a generic model pipeline for structured data and fit and predict.</p>\n\n<p>For details of what the generic model pipeline does, please check\n<code>make_generic_model_pipeline</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  DataFrame of features (x_col) and target variable (y_col)</li>\n<li><strong>y_col:</strong>  name of prediction target column.</li>\n<li><strong>x_cols:</strong>  list of feature column names.\nNote: The optinal_cols should not be included in this list.</li>\n<li><strong>model_class:</strong>  Any classifier or regressor sklearn object.</li>\n<li><strong>params:</strong>  either a dictionary of values, or a dictionary of list\nof values. If the latter, the model pipeline will be wrapped\nin a  GridSearch.</li>\n<li><strong>cv:</strong>  <code>cv</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>scoring:</strong>  <code>scoring</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>refit:</strong>  <code>refit</code> parameter from <code>sklearn.model_selection.GridSearch</code></li>\n<li><strong>calib_method:</strong>  provide one of {\"sigmoid\", \"isotonic\"} if you are\nusing a classifier which does not produce calibrated\nprobabilities (i.e. non-GLM methods)</li>\n<li><strong>model_n_jobs:</strong>  <code>n_jobs</code> arg for the model (defaults to -1)</li>\n<li><strong>gs_n_jobs:</strong>  <code>n_jobs</code> arg for gridsearch (defaults to -1)</li>\n<li><strong>search_type:</strong>  Type of hyperparameter search.\nOptions:\n   None   -> No Hyper parameter optimization.\n   grid   -> GridSearchCV\n   bayes  -> BayesSearchCV\n   random -> RandomizedSearchCV\nDefaults to None but will use grid search if parameters are all lists.</li>\n<li><strong>n_iter:</strong>  Number of model tuning iterations for Randomized and Bayesian search.</li>\n<li><strong>num_preproc:</strong>  Numerical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_NUM_PREPROC</code>.</li>\n<li><strong>ctg_preproc:</strong>  Categorical preprocessing pipeline. The default is None and will\nuse <code>DEFAULT_CTG_PREPROC</code>.</li>\n<li><strong>treatment_col:</strong>  Treatment column in uplifft model not included in\npre-processing.</li>\n<li><strong>model_pipeline:</strong>  A pre-trained random forest model pipeline allowing warm_start.</li>\n<li><strong>extra_estimators:</strong>  Extra estimators added to fit the model with more data.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A tuple of the fitted model pipeline plus the predictions DataFrame.</p>\n</blockquote>\n", "signature": "(\n    df: pandas.core.frame.DataFrame,\n    y_col: str,\n    x_cols: List[str],\n    model_class: sklearn.base.BaseEstimator,\n    params: Union[Dict[str, Union[str, float, List[Union[str, float]]]], NoneType] = None,\n    cv: Union[int, sklearn.model_selection._split.BaseCrossValidator, Iterator, NoneType] = None,\n    scoring: Union[str, Callable, List, Tuple, Dict, NoneType] = None,\n    refit: Union[bool, str, Callable, NoneType] = None,\n    calib_method: Union[str, NoneType] = None,\n    model_n_jobs: Union[int, NoneType] = -1,\n    gs_n_jobs: Union[int, NoneType] = -1,\n    search_type: Union[str, NoneType] = None,\n    n_iter: Union[int, NoneType] = None,\n    num_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    ctg_preproc: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    treatment_col: str = None,\n    model_pipeline: Union[sklearn.pipeline.Pipeline, NoneType] = None,\n    extra_estimators: int = 100\n) -> Tuple[sklearn.pipeline.Pipeline, pandas.core.frame.DataFrame]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils", "modulename": "pipeline.udeml.utils.smdeployutils", "type": "module", "doc": "<p>Utilities related to SageMaker.</p>\n"}, {"fullname": "pipeline.udeml.utils.smdeployutils.PySparkProcessorWithBootstrap", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "PySparkProcessorWithBootstrap", "type": "class", "doc": "<p>Handles Amazon SageMaker processing tasks for jobs using PySpark.</p>\n", "bases": "sagemaker.spark.processing.PySparkProcessor"}, {"fullname": "pipeline.udeml.utils.smdeployutils.PySparkProcessorWithBootstrap.run", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "PySparkProcessorWithBootstrap.run", "type": "function", "doc": "<p>Runs a processing job.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>submit_app (str):</strong>  Path (local or S3) to Python file to submit to Spark\nas the primary application</li>\n<li><strong>submit_py_files (list[str]):</strong>  List of paths (local or S3) to provide for\n<code>spark-submit --py-files</code> option</li>\n<li><strong>submit_jars (list[str]):</strong>  List of paths (local or S3) to provide for\n<code>spark-submit --jars</code> option</li>\n<li><strong>submit_files (list[str]):</strong>  List of paths (local or S3) to provide for\n<code>spark-submit --files</code> option</li>\n<li><strong>bootstrap_script (str):</strong>  Path (local or S3) to shell script to run on all\nnodes when they startup</li>\n<li><strong>inputs (list[<code>~sagemaker.processing.ProcessingInput</code>]):</strong>  Input files\nfor the processing job. These must be provided as\n<code>~sagemaker.processing.ProcessingInput</code> objects (default: None).</li>\n<li><strong>outputs (list[<code>~sagemaker.processing.ProcessingOutput</code>]):</strong>  Outputs for\nthe processing job. These can be specified as either path strings or\n<code>~sagemaker.processing.ProcessingOutput</code> objects (default: None).</li>\n<li><strong>arguments (list[str]):</strong>  A list of string arguments to be passed to a\nprocessing job (default: None).</li>\n<li><strong>wait (bool):</strong>  Whether the call should wait until the job completes\n(default: True).</li>\n<li><strong>logs (bool):</strong>  Whether to show the logs produced by the job.\nOnly meaningful when wait is True (default: True).</li>\n<li><strong>job_name (str):</strong>  Processing job name. If not specified, the processor\ngenerates a default job name, based on the base job name and current\ntimestamp.</li>\n<li><strong>experiment_config (dict[str, str]):</strong>  Experiment management configuration.\nDictionary contains three optional keys:\n'ExperimentName', 'TrialName', and 'TrialComponentDisplayName'.</li>\n<li><strong>configuration (list[dict] or dict):</strong>  Configuration for Hadoop, Spark, or\nHive. List or dictionary of EMR-style classifications.\nhttps://docs-old.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html</li>\n<li><strong>spark_event_logs_s3_uri (str):</strong>  S3 path where spark application events will\nbe published to.</li>\n<li><strong>kms_key (str):</strong>  The ARN of the KMS key that is used to encrypt the\nuser code file (default: None).</li>\n</ul>\n", "signature": "(\n    self,\n    submit_app,\n    submit_py_files=None,\n    submit_jars=None,\n    submit_files=None,\n    bootstrap_script=None,\n    inputs=None,\n    outputs=None,\n    arguments=None,\n    wait=True,\n    logs=True,\n    job_name=None,\n    experiment_config=None,\n    configuration=None,\n    spark_event_logs_s3_uri=None,\n    kms_key=None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.CustomProcessor", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "CustomProcessor", "type": "class", "doc": "<p>Handles Amazon SageMaker processing tasks for jobs using custom images</p>\n", "bases": "sagemaker.processing.ScriptProcessor"}, {"fullname": "pipeline.udeml.utils.smdeployutils.CustomProcessor.__init__", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "CustomProcessor.__init__", "type": "function", "doc": "<p>Initialize an <code>CustomProcessor</code> instance.</p>\n\n<p>The CustomProcessor handles Amazon SageMaker processing tasks for jobs\nusing custom images.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>framework_version (str):</strong>  Custom image name in {ecr_repository_name:tag}\nformat. This information is used when setting the full image uri.</li>\n<li><strong>role (str):</strong>  An AWS IAM role name or ARN. The Amazon SageMaker training jobs\nand APIs that create Amazon SageMaker endpoints use this role\nto access training data and model artifacts. After the endpoint\nis created, the inference code might use the IAM role, if it\nneeds to access an AWS resource.</li>\n<li><strong>instance_type (str):</strong>  Type of EC2 instance to use for\nprocessing, for example, 'ml.c4.xlarge'.</li>\n<li><strong>instance_count (int):</strong>  The number of instances to run\nthe Processing job with. Defaults to 1.</li>\n<li><strong>command ([str]):</strong>  The command to run, along with any command-line flags.\nExample: [\"python3\", \"-v\"]. If not provided, [\"python3\"] or [\"python2\"]\nwill be chosen based on the py_version parameter.</li>\n<li><strong>volume_size_in_gb (int):</strong>  Size in GB of the EBS volume to\nuse for storing data during processing (default: 30).</li>\n<li><strong>volume_kms_key (str):</strong>  A KMS key for the processing\nvolume.</li>\n<li><strong>output_kms_key (str):</strong>  The KMS key id for all ProcessingOutputs.</li>\n<li><strong>max_runtime_in_seconds (int):</strong>  Timeout in seconds.\nAfter this amount of time Amazon SageMaker terminates the job\nregardless of its current status.</li>\n<li><strong>base_job_name (str):</strong>  Prefix for processing name. If not specified,\nthe processor generates a default job name, based on the\ntraining image name and current timestamp.</li>\n<li><strong>sagemaker_session (sagemaker.session.Session):</strong>  Session object which\nmanages interactions with Amazon SageMaker APIs and any other\nAWS services needed. If not specified, the processor creates one\nusing the default AWS configuration chain.</li>\n<li><strong>env (dict):</strong>  Environment variables to be passed to the processing job.</li>\n<li><strong>tags ([dict]):</strong>  List of tags to be passed to the processing job.</li>\n<li><strong>network_config (sagemaker.network.NetworkConfig):</strong>  A NetworkConfig\nobject that configures network isolation, encryption of\ninter-container traffic, security group IDs, and subnets.</li>\n</ul>\n", "signature": "(\n    self,\n    framework_version,\n    role,\n    instance_type,\n    instance_count,\n    command=None,\n    volume_size_in_gb=30,\n    volume_kms_key=None,\n    output_kms_key=None,\n    max_runtime_in_seconds=None,\n    base_job_name=None,\n    sagemaker_session=None,\n    env=None,\n    tags=None,\n    network_config=None\n)", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.epoch_ms_to_dt_str", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "epoch_ms_to_dt_str", "type": "function", "doc": "<p>Get string date from epoch in milliseconds.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>epoch_ms:</strong>  numeric representing milliseconds since Unix epoch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Local date and time in format \"yyyy-mm-dd hh:MM:SS.sss\"</p>\n</blockquote>\n", "signature": "(epoch_ms: float) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.get_log_events", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "get_log_events", "type": "function", "doc": "<p>Get all event logs for a particular log stream name.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>stream_name:</strong>  AWS log stream name.</li>\n<li><strong>group_name:</strong>  AWS log group name (defaults to \"/aws/sagemaker/ProcessingJobs\")</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of tuples where first element is timestamp of the event\n  in string format and second element is the even log message.</p>\n</blockquote>\n", "signature": "(\n    stream_name: str,\n    group_name: str = '/aws/sagemaker/ProcessingJobs'\n) -> List[Tuple[str, str]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.describe_log_streams", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "describe_log_streams", "type": "function", "doc": "<p>Get all stream names for a given prefix (a.k.a job name)</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>stream_name_prefix:</strong>  prefix for the log stream names. Hint: if you\nrun a processing job with multiple instances, all the stream\nnames will start with the job name.</li>\n<li><strong>group_name:</strong>  AWS log group name (defaults to \"/aws/sagemaker/ProcessingJobs\")</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of stream names sharing the same beginning.</p>\n</blockquote>\n", "signature": "(\n    stream_name_prefix: str,\n    group_name: str = '/aws/sagemaker/ProcessingJobs'\n) -> List[str]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.get_merged_logs", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "get_merged_logs", "type": "function", "doc": "<p>Get merged logs for a job with multiple instances.</p>\n\n<p>Note: This assumes that all the logs stream names for a given job are in format\n<job_name>/<instance_specific_name></p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>job_name:</strong>  job name which should be prefix for all log streams.</li>\n<li><strong>group_name:</strong>  AWS log group name (defaults to \"/aws/sagemaker/ProcessingJobs\")</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>List of tuples containing the timestamp, instance-specific name, and the log\n  message.</p>\n</blockquote>\n", "signature": "(\n    job_name: str,\n    group_name: str = '/aws/sagemaker/ProcessingJobs'\n) -> List[Tuple[str, str, str]]", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smdeployutils.write_merged_logs", "modulename": "pipeline.udeml.utils.smdeployutils", "qualname": "write_merged_logs", "type": "function", "doc": "<p>Get merged logs for a job with multiple instances.</p>\n\n<p>Note: This assumes that all the logs stream names for a given job are in format\n<job_name>/<instance_specific_name></p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>job_name:</strong>  job name which should be prefix for all log streams.</li>\n<li><strong>group_name:</strong>  AWS log group name (defaults to \"/aws/sagemaker/ProcessingJobs\")</li>\n<li><strong>log_dir:</strong>  directory to write the log to. Note: will create it if it does not\nexist so be careful. (defaults to /tmp/logs)</li>\n<li><strong>gzipped:</strong>  Whether the output file should be gzipped or not. (defaults to True)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Path to the log file written.</p>\n</blockquote>\n", "signature": "(\n    job_name: str,\n    group_name: str = '/aws/sagemaker/ProcessingJobs',\n    log_dir: str = '/tmp/logs',\n    gzipped: bool = True\n) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils", "modulename": "pipeline.udeml.utils.smpysparkutils", "type": "module", "doc": "<p>Utilities related to SageMaker PySpark utilities.</p>\n"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel", "type": "class", "doc": "<p>ENUM to hold the allowed values for Spark log level</p>\n", "bases": "enum.Enum"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.TRACE", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.TRACE", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.TRACE: 'TRACE'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.DEBUG", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.DEBUG", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.DEBUG: 'DEBUG'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.INFO", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.INFO", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.INFO: 'INFO'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.WARN", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.WARN", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.WARN: 'WARN'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.ERROR", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.ERROR", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.ERROR: 'ERROR'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.SparkLogLevel.FATAL", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "SparkLogLevel.FATAL", "type": "variable", "doc": "<p></p>\n", "default_value": " = <SparkLogLevel.FATAL: 'FATAL'>"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.get_spark", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "get_spark", "type": "function", "doc": "<p>Creates a spark session.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>spark_defaults_dict:</strong>  See parameter <code>spark_defaults_dict</code>\nin <code>udeml.utils.configutils.get_spark_defaults_config</code>.</li>\n<li><strong>spark_defaults_file_path:</strong>  See parameter <code>spark_defaults_file_path</code>\nin <code>udeml.utils.configutils.get_spark_defaults_config</code>.</li>\n<li><strong>spark_log_level:</strong>  spark log level</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Spark session</p>\n</blockquote>\n", "signature": "(\n    spark_defaults_dict: Union[Dict, NoneType] = None,\n    spark_defaults_file_path: Union[str, NoneType] = None,\n    spark_log_level: pipeline.udeml.utils.smpysparkutils.SparkLogLevel = None\n) -> pyspark.sql.session.SparkSession", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.get_final_spark_defaults_config", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "get_final_spark_defaults_config", "type": "function", "doc": "<p>Returns the final version of the spark-defaults configuration\nwhich will be used by the application.</p>\n\n<p>It gets the application-specific config and then updates it with\nthe common configuration properties.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>spark_defaults_dict:</strong>  See parameter <code>spark_defaults_dict</code>\nin <code>udeml.utils.configutils.get_spark_defaults_config</code>.</li>\n<li><strong>spark_defaults_file_path:</strong>  See parameter <code>spark_defaults_file_path</code>\nin <code>udeml.utils.configutils.get_spark_defaults_config</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Dictionary containing spark-defaults configuration</p>\n</blockquote>\n", "signature": "(\n    spark_defaults_dict: Union[Dict, NoneType] = None,\n    spark_defaults_file_path: Union[str, NoneType] = None\n) -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.get_common_config", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "get_common_config", "type": "function", "doc": "<p>Returns common config properties which will used by all applications</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Common spark-defaults dictionary</p>\n</blockquote>\n", "signature": "() -> Dict", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.get_hadoop_aws_version", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "get_hadoop_aws_version", "type": "function", "doc": "<p>Gets the hadoop-aws jar version compatible with the given PySpark version.</p>\n\n<p>hadoop-aws version must be compatible\nwith the hadoop-common version installed with PySpark.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>pyspark_version:</strong>  pyspark version in x.y.z format.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Full name of the hadoop-aws jar with the spark-compatible version.</p>\n</blockquote>\n", "signature": "(pyspark_version: str) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.get_credentials_provider", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "get_credentials_provider", "type": "function", "doc": "<p>Gets the name of the correct AWS credentials implementation\nby checking if the code runs on local or remote.</p>\n\n<p>Credentials are loaded from the Amazon EC2 Instance Metadata Service for local,\nand from an Amazon Elastic Container for remote.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>local_or_remote:</strong>  information showing that the code runs on local or remote.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Full name of the AWS credentials implementation.</p>\n</blockquote>\n", "signature": "(local_or_remote: str) -> str", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.smpysparkutils.write_spark_df_to_hive", "modulename": "pipeline.udeml.utils.smpysparkutils", "qualname": "write_spark_df_to_hive", "type": "function", "doc": "<p>Writes spark dataframe to s3 and hive.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>df:</strong>  spark dataframe.</li>\n<li><strong>output_s3_path:</strong>  output s3 path.</li>\n<li><strong>output_database:</strong>  output database.</li>\n<li><strong>output_table:</strong>  output table.</li>\n<li><strong>partition_cols:</strong>  names of partitioning columns.\n(defaults to None, meaning that there will no partitions)</li>\n<li><strong>compression:</strong>  compression codec to use when saving to file.\nThis can be one of the known case-insensitive shorten names\n(none, bzip2, gzip, lz4, snappy and deflate)</li>\n<li><strong>format:</strong>  name of the data source, e.g. 'json', 'parquet', 'csv'.</li>\n<li><strong>mode:</strong>  specifies the behavior of the save operation when data already exists.\n<ul>\n<li>append: Append contents of this DataFrame to existing data.</li>\n<li>overwrite: Overwrite existing data.</li>\n<li>ignore: Silently ignore this operation if data already exists.</li>\n<li>error: Throw an exception if data already exists.</li>\n</ul></li>\n<li><strong>sep:</strong>  Sets a separator for each field and value.\nThis separator can be one or more characters. This argument is\neffective only if the format is 'csv'.</li>\n</ul>\n", "signature": "(\n    df: pyspark.sql.dataframe.DataFrame,\n    output_s3_path: str,\n    output_database: str,\n    output_table: str,\n    partition_cols: Union[List[str], NoneType] = None,\n    compression: str = 'snappy',\n    format: str = 'parquet',\n    mode: str = 'overwrite',\n    sep: str = '\\t'\n) -> None", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.spark_app_runner", "modulename": "pipeline.udeml.utils.spark_app_runner", "type": "module", "doc": "<p>Utilities for running spark apps</p>\n"}, {"fullname": "pipeline.udeml.utils.spark_app_runner.run", "modulename": "pipeline.udeml.utils.spark_app_runner", "qualname": "run", "type": "function", "doc": "<p>Creates a spark context and run an app that inherits from SparkApp by passing\nthe spark context.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>module_name:</strong>  A python module that has the spark app to run</li>\n<li><strong>class_name:</strong>  A class name that must inherit from SparkApp.</li>\n<li><strong>function_name:</strong>  Function name of the class that will be called.</li>\n<li><strong>application_args:</strong>  Dictionary of the application arguments to pass the class</li>\n</ul>\n", "signature": "(\n    module_name: str,\n    class_name: str,\n    function_name: str,\n    application_args: Dict\n) -> None", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.spark_app_runner.get_args", "modulename": "pipeline.udeml.utils.spark_app_runner", "qualname": "get_args", "type": "function", "doc": "<p>Get command line arguments.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Tuple where first element is namespace of known args, and second element\n  is a dictionary of the remaining (unknown) args.</p>\n</blockquote>\n", "signature": "()", "funcdef": "def"}, {"fullname": "pipeline.udeml.utils.spark_app_runner.main", "modulename": "pipeline.udeml.utils.spark_app_runner", "qualname": "main", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();